'''
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â• â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
â•šâ•â•â•â•â•â•â•   â•šâ•â•   â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â•
'''
import json
import faiss
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from transformers import AutoModel, StoppingCriteria, StoppingCriteriaList
import gradio as gr

# ========== é…ç½® ==========
LLM_PATH = "./Qwen2.5-7B"  # Qwen2.5-7B æ¨¡å‹è·¯å¾„
M3E_PATH = "./m3e-base"  # m3e å‘é‡åŒ–æ¨¡å‹è·¯å¾„
FAISS_INDEX_FILE = "fraud_sms_faiss.index"  # FAISS ç´¢å¼•æ–‡ä»¶
METADATA_FILE = "fraud_sms_metadata.json"  # å…ƒæ•°æ®æ–‡ä»¶
DEVICE = "cuda"
SAFE_MODE = False  # True: ç¨³å¦¥æ¨¡å¼ï¼ˆä¸‰æ¬¡é¢„æµ‹å–å¤šæ•°ï¼‰ï¼ŒFalse: æ™®é€šæ¨¡å¼ï¼ˆå•æ¬¡é¢„æµ‹ï¼‰
DE_BUG = False  # æ˜¾ç¤ºæ¨¡å‹åŸå§‹è¾“å‡ºå¼€å…³
SHOW_CATEGORY = False  # è¾“å‡ºç”„åˆ«ç±»åˆ«å¼€å…³
SHOW_SAMPLE = True  # è¾“å‡ºç›¸ä¼¼çŸ­ä¿¡å¼€å…³
MAX_TOKENS = 512  # æ¨¡å‹æœ€å¤§è¾“å‡ºé•¿åº¦
MAX_RETRIES = 0  # è¾“å‡ºå¼‚å¸¸æœ€å¤§é‡è¯•æ•°

# ========== åŠ è½½ Qwen2.5-7B ==========
# 6Gæ˜¾å­˜ä¼˜åŒ–é…ç½®ï¼Œå®æµ‹è¿è¡Œå ç”¨5.8Gæ˜¾å­˜
print("åŠ è½½ Qwen2.5-7B...")
quant_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_storage=torch.uint8,     # æ˜¾å¼å£°æ˜å­˜å‚¨ç±»å‹
    llm_int8_enable_fp32_cpu_offload=True   # å¼ºåˆ¶å¯ç”¨CPUå¸è½½
)
llm_tokenizer = AutoTokenizer.from_pretrained(LLM_PATH, trust_remote_code=True)
llm_model = AutoModelForCausalLM.from_pretrained(
    LLM_PATH,
    quantization_config=quant_config,
    device_map="auto",
    torch_dtype=torch.float16,
    max_memory={0: "5GiB"},
    offload_folder="./offload_temp"
).eval()

# ========== åŠ è½½ FAISS ç´¢å¼• ==========
print("åŠ è½½ FAISS ç´¢å¼•...")
index = faiss.read_index(FAISS_INDEX_FILE)
with open(METADATA_FILE, "r", encoding="utf-8") as f:
    metadata = json.load(f)

# ========== å®šä¹‰çŸ­ä¿¡ç±»åˆ« ==========
LABELS = [
    "æ­£å¸¸çŸ­ä¿¡",
    "å†’å……å…¬æ£€æ³•",
    "è´·æ¬¾è¯ˆéª—",
    "å†’å……å®¢æœ",
    "å†’å……é¢†å¯¼æˆ–ç†Ÿäººè¯ˆéª—"
]

# ========== åŠ è½½ m3e å‘é‡åŒ–æ¨¡å‹ ==========
print("åŠ è½½ m3e å‘é‡åŒ–æ¨¡å‹...")
tokenizer = AutoTokenizer.from_pretrained(M3E_PATH)
model = AutoModel.from_pretrained(M3E_PATH).to(DEVICE).eval()


@torch.no_grad()
def get_embedding(text: str):
    """è·å–æ–‡æœ¬çš„ m3e åµŒå…¥å‘é‡"""
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512).to(DEVICE)
    outputs = model(**inputs)
    embedding = outputs.last_hidden_state.mean(dim=1)
    return embedding.squeeze().cpu().numpy()


# ========== RAG æ£€ç´¢ ==========
def retrieve_similar_texts(query, top_k=5):
    """æ£€ç´¢ä¸æŸ¥è¯¢çŸ­ä¿¡æœ€ç›¸ä¼¼çš„ top_k æ¡çŸ­ä¿¡"""
    query_vec = get_embedding(query).reshape(1, -1)
    distances, indices = index.search(query_vec, top_k)
    results = [metadata[idx] for idx in indices[0] if idx < len(metadata)]
    return results


# ========== è‡ªå®šä¹‰åœæ­¢æ¡ä»¶ ==========
class DynamicStoppingCriteria(StoppingCriteria):
    """åŠ¨æ€åœæ­¢æ¡ä»¶ï¼šå½“ç”Ÿæˆæœ‰æ•ˆ ``` å—æ—¶åœæ­¢"""

    def __init__(self, tokenizer):
        self.tokenizer = tokenizer

    def __call__(self, input_ids, scores, **kwargs):
        decoded_text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True)
        if "```" in decoded_text:
            blocks = decoded_text.split("```")
            for i in range(1, len(blocks), 2):  # æ£€æŸ¥æ¯ä¸ªå†…å®¹å—
                block = blocks[i].strip()
                if block:
                    lines = block.split("\n")
                    has_label = False
                    has_reason = False
                    label_valid = False
                    reason_valid = False
                    for line in lines:
                        line = line.strip()
                        if line.startswith("é¢„æµ‹ç±»åˆ«:"):
                            has_label = True
                            label = line.split("é¢„æµ‹ç±»åˆ«:")[1].strip()
                            label_valid = "<ç±»åˆ«åç§°>" not in label and label != "æœªçŸ¥" and label
                        elif line.startswith("ç†ç”±:"):
                            has_reason = True
                            reason = line.split("ç†ç”±:")[1].strip()
                            reason_valid = "<ç®€çŸ­ç†ç”±" not in reason and reason != "æœªæä¾›ç†ç”±" and reason
                    if has_label and has_reason and label_valid and reason_valid and decoded_text.endswith("```"):
                        return True
        return False


# ========== å•æ¬¡åˆ†ç±»å‡½æ•° ==========
def single_classify(sms_text, similar_texts, attempt_num):
    """å•æ¬¡çŸ­ä¿¡åˆ†ç±»ï¼ŒåŒ…å«é‡è¯•é€»è¾‘"""
    retrieved_examples = "\n".join(
        [f"- çŸ­ä¿¡: {item['text']} | ç±»åˆ«: {item['label']}" for item in similar_texts]
    ) if (similar_texts and similar_texts != " ") else "æ— ç›¸ä¼¼çŸ­ä¿¡ç¤ºä¾‹ã€‚"

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªç²¾å‡†çš„æ™ºèƒ½çŸ­ä¿¡åˆ†ç±»åŠ©æ‰‹ï¼Œæ“…é•¿è¯ˆéª—çŸ­ä¿¡ç”„åˆ«ã€‚è¯·ä¾æ®ä»¥ä¸‹åˆ†ç±»æ­¥éª¤ç”Ÿæˆä¸€ä¸ªæœ‰æ•ˆçš„ ``` å—ç»“æœï¼Œä¸è¾“å‡ºå¤šä½™ä¿¡æ¯ã€‚ç¡®ä¿ä»¥ ``` å¼€å§‹å’Œç»“æŸï¼ŒåŒ…å«â€œé¢„æµ‹ç±»åˆ«:â€ã€â€œç†ç”±:â€ï¼Œä¸å«å ä½ç¬¦ï¼ˆå¦‚ <ç±»åˆ«åç§°>ï¼‰ã€‚ç”Ÿæˆç¬¬ä¸€ä¸ªæœ‰æ•ˆå—åç«‹å³åœæ­¢ã€‚

    åˆ†ç±»æ­¥éª¤ï¼š
    1. åˆ†æçŸ­ä¿¡ç‰¹å¾ï¼šå…³æ³¨è¯­æ°”ï¼ˆæ­£å¼/éšæ„ï¼‰ã€ç”¨è¯ï¼ˆæ˜¯å¦æ¶‰åŠé‡‘é’±ã€ç´§æ€¥ã€èº«ä»½å†’å……ï¼‰ã€æ˜¯å¦æœ‰æ•æ„Ÿè¡ŒåŠ¨è¦æ±‚ï¼ˆå¦‚è½¬è´¦ã€æä¾›ä¿¡æ¯ï¼‰ã€‚
    2. â€œå†’å……å®¢æœâ€è¯†åˆ«ï¼šæ³¨æ„å‡å†’å®¢æœå¸¸ä½¿ç”¨ä¼ªä¸“ä¸šè¯­æ°”ã€è¦æ±‚ç‚¹å‡»é“¾æ¥éªŒè¯èº«ä»½æˆ–æ±‡æ¬¾ç­‰æ“ä½œï¼Œè€Œæ­£å¸¸å®¢æœè¯­æ°”å¹³ç¨³ã€æ— æ•æ„Ÿç´¢å–ï¼Œéœ€è¦æ³¨æ„å’Œå†’å……å…¬æ£€æ³•ã€å†’å……é¢†å¯¼æˆ–ç†Ÿäººè¯ˆéª—ã€æ­£å¸¸çŸ­ä¿¡çš„åŒºåˆ†
    3. â€œå†’å……é¢†å¯¼æˆ–ç†Ÿäººè¯ˆéª—â€å…·æœ‰æ˜ç¡®çš„èµ„é‡‘æˆ–æ•æ„Ÿæ•°æ®è¦æ±‚ï¼Œå°†å…¶ä¸â€œæ­£å¸¸çŸ­ä¿¡â€åŒºåˆ†å¼€ï¼Œå•çº¯è¾±éª‚çš„çŸ­ä¿¡ä¸å±äºè¯ˆéª—ã€‚
    4. å‚è€ƒç›¸ä¼¼çŸ­ä¿¡ï¼šç»“åˆç¤ºä¾‹çš„ç±»åˆ«åˆ†å¸ƒï¼Œè¯„ä¼°è¾“å…¥çŸ­ä¿¡ä¸ç¤ºä¾‹çš„ç›¸ä¼¼æ€§ã€‚
    5. é€»è¾‘æ¨ç†ï¼šåŸºäºç‰¹å¾å’Œç¤ºä¾‹ï¼Œå¾—å‡ºæœ€å¯èƒ½çš„ç±»åˆ«ã€‚

    è¾“å…¥ä¿¡æ¯ï¼š
    çŸ­ä¿¡å†…å®¹: "{sms_text}"
    ç›¸ä¼¼çŸ­ä¿¡ç¤ºä¾‹ï¼š
    {retrieved_examples}

    çŸ­ä¿¡ç±»åˆ«é€‰é¡¹ï¼š
    1. æ­£å¸¸çŸ­ä¿¡ï¼ˆæ—¥å¸¸é€šçŸ¥ã€æœåŠ¡ç¡®è®¤ã€ä¿ƒé”€ç­‰ï¼‰
    2. å†’å……å…¬æ£€æ³•ï¼ˆå‡è£…æ‰§æ³•æœºæ„ï¼Œæå“æˆ–ç´¢è¦ä¿¡æ¯ï¼‰
    3. è´·æ¬¾è¯ˆéª—ï¼ˆæ¶‰åŠè´·æ¬¾ã€ä¼˜æƒ æ¡ä»¶è¯±å¯¼è½¬è´¦ï¼‰
    4. å†’å……å®¢æœï¼ˆå‡å†’æœåŠ¡äººå‘˜ç´¢è¦ä¿¡æ¯æˆ–é’±è´¢ï¼‰
    5. å†’å……é¢†å¯¼æˆ–ç†Ÿäººè¯ˆéª—ï¼ˆå‡è£…ç†Ÿäººæˆ–ä¸Šçº§è¦æ±‚è½¬è´¦ï¼‰

    è¾“å‡ºæ ¼å¼ï¼š
    ```
    é¢„æµ‹ç±»åˆ«: <ç±»åˆ«åç§°>
    ç†ç”±: <ç®€çŸ­ç†ç”±ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼Œè¯´æ˜ç‰¹å¾å’Œæ¨ç†ä¾æ®>
    ```
    """

    stopping_criteria = StoppingCriteriaList([DynamicStoppingCriteria(llm_tokenizer)])

    for retry in range(MAX_RETRIES + 1):
        inputs = llm_tokenizer(prompt, return_tensors="pt").to(DEVICE)
        outputs = llm_model.generate(
            **inputs,
            max_new_tokens=MAX_TOKENS,
            do_sample=False,
            pad_token_id=llm_tokenizer.eos_token_id,
            stopping_criteria=stopping_criteria
        )
        response = llm_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
        if DE_BUG:
            print(f"ğŸ“ å°è¯• {attempt_num} - é‡è¯• {retry + 1} æ¨¡å‹è¾“å‡ºï¼š")
            print(response)

        pred_label = "æœªçŸ¥"
        reason = "æœªæä¾›ç†ç”±"
        similar_sms = "æ— "

        if "```" in response:
            blocks = response.split("```")
            for i in range(1, len(blocks), 2):
                block = blocks[i].strip()
                if block:
                    lines = block.split("\n")
                    temp_label = "æœªçŸ¥"
                    temp_reason = "æœªæä¾›ç†ç”±"
                    for line in lines:
                        line = line.strip()
                        if line.startswith("é¢„æµ‹ç±»åˆ«:"):
                            temp_label = line.split("é¢„æµ‹ç±»åˆ«:")[1].strip()
                        elif line.startswith("ç†ç”±:"):
                            temp_reason = line.split("ç†ç”±:")[1].strip()
                    if ("<ç±»åˆ«åç§°>" not in temp_label and
                            "<ç®€çŸ­ç†ç”±" not in temp_reason and
                            temp_label != "æœªçŸ¥" and
                            temp_reason != "æœªæä¾›ç†ç”±"):
                        pred_label = temp_label
                        reason = temp_reason
                        for item in similar_texts:
                            if item["label"] == pred_label:
                                similar_sms = item["text"]
                                break
                        break

        if pred_label == "æœªçŸ¥" or reason == "æœªæä¾›ç†ç”±":
            if retry < MAX_RETRIES:
                print(f"âš ï¸ å°è¯• {attempt_num} - é‡è¯• {retry + 1} è¾“å‡ºä¸ºæ¨¡æ¿æˆ–æ— æ•ˆï¼Œé‡è¯•ä¸­...")
                continue
            else:
                print(f"âŒ å°è¯• {attempt_num} - æ¨¡å‹å¼‚å¸¸ï¼Œé‡è¯• {MAX_RETRIES} æ¬¡åä»æ— æ•ˆ")
                return None, None, None
        else:
            return pred_label, reason, similar_sms


# ========== Qwen2.5 è¿›è¡Œåˆ†ç±» ==========
def classify_sms(sms_text, history=None):
    """ä¸»åˆ†ç±»å‡½æ•°ï¼Œæ”¯æŒæ™®é€šå’Œç¨³å¦¥æ¨¡å¼"""
    if not sms_text.strip():
        return "è¯·è¾“å…¥çŸ­ä¿¡å†…å®¹ï¼", history or []

    if history is None:
        history = []

    similar_texts = retrieve_similar_texts(sms_text)
    if not similar_texts:
        print("âš ï¸ æœªæ£€ç´¢åˆ°ç›¸ä¼¼çŸ­ä¿¡ï¼Œä½¿ç”¨é»˜è®¤é€»è¾‘åˆ†ç±»ã€‚")

    output_lines = []
    if not SAFE_MODE:
        pred_label, reason, similar_sms = single_classify(sms_text, similar_texts, 1)
        if pred_label is None:
            output_lines.append("âŒ æ¨¡å‹è¾“å‡ºå¼‚å¸¸")
        else:
            if pred_label != 'æ­£å¸¸çŸ­ä¿¡':
                output_lines.append('ğŸ›‘ è­¦å‘Šï¼Œè¿™æ˜¯è¯ˆéª—çŸ­ä¿¡â—â—â—')
            else:
                output_lines.append('ğŸŸ¢æ­£å¸¸çŸ­ä¿¡')
            if SHOW_CATEGORY:
                output_lines.append(f"ğŸ¯ ç±»åˆ«: {pred_label}")
            output_lines.append(f"ç†ç”±: {reason}")
            if SHOW_SAMPLE:
                output_lines.append(f"ç›¸ä¼¼{'è¯ˆéª—' if pred_label != 'æ­£å¸¸çŸ­ä¿¡' else ''}çŸ­ä¿¡: {similar_sms}")
    else:
        results = []
        for attempt in range(3):
            pred_label, reason, similar_sms = single_classify(sms_text, similar_texts, attempt + 1)
            if pred_label is None:
                output_lines.append("âŒ æ¨¡å‹è¾“å‡ºå¼‚å¸¸")
                break
            results.append((pred_label, reason, similar_sms))

            if attempt == 1 and results[0][0] == results[1][0]:
                if pred_label != 'æ­£å¸¸çŸ­ä¿¡':
                    output_lines.append('ğŸ›‘ è­¦å‘Šï¼Œè¿™æ˜¯è¯ˆéª—çŸ­ä¿¡â—â—â—')
                else:
                    output_lines.append('ğŸŸ¢æ­£å¸¸çŸ­ä¿¡')
                if SHOW_CATEGORY:
                    output_lines.append(f"ğŸ¯ ç±»åˆ«: {pred_label}")
                output_lines.append(f"ç†ç”±: {reason}")
                if SHOW_SAMPLE:
                    output_lines.append(f"ç›¸ä¼¼{'è¯ˆéª—' if pred_label != 'æ­£å¸¸çŸ­ä¿¡' else ''}çŸ­ä¿¡: {similar_sms}")
                break
            elif attempt == 2:
                if results[0][0] != results[1][0] and results[1][0] != results[2][0] and results[0][0] != results[2][0]:
                    output_lines.append("â“ ç¨³å¦¥æ¨¡å¼ä¸‹ä¸‰æ¬¡é¢„æµ‹ä¸ä¸€è‡´ï¼Œæ— æ³•åˆ¤æ–­")
                else:
                    final_label = max(set([r[0] for r in results]), key=[r[0] for r in results].count)
                    final_result = next(r for r in results if r[0] == final_label)
                    if final_label != 'æ­£å¸¸çŸ­ä¿¡':
                        output_lines.append('ğŸ›‘ è­¦å‘Šï¼Œè¿™æ˜¯è¯ˆéª—çŸ­ä¿¡â—â—â—')
                    else:
                        output_lines.append('ğŸŸ¢æ­£å¸¸çŸ­ä¿¡')
                    if SHOW_CATEGORY:
                        output_lines.append(f"ğŸ¯ ç±»åˆ«: {final_label}")
                    output_lines.append(f"ç†ç”±: {final_result[1]}")
                    if SHOW_SAMPLE:
                        output_lines.append(f"ç›¸ä¼¼{'è¯ˆéª—' if final_label != 'æ­£å¸¸çŸ­ä¿¡' else ''}çŸ­ä¿¡: {final_result[2]}")

    output = "\n".join(output_lines)
    history.append({"role": "user", "content": sms_text})
    history.append({"role": "assistant", "content": output})
    print("History:", history)
    return output, history


# ========== Gradio ç•Œé¢ ==========
def create_interface():
    """åˆ›å»º Gradio å¯è§†åŒ–ç•Œé¢"""
    mode_info = """
    By: stlin256 
    å½“å‰æ¨¡å¼: ç¨³å¦¥æ¨¡å¼
    è¯´æ˜ï¼šåœ¨å½“å‰æ¨¡å¼ä¸‹ï¼Œæ¯æ¡çŸ­ä¿¡éƒ½ä¼šè¢«è‡³å°‘ç”„åˆ«ä¸¤æ¬¡ï¼Œè‹¥ä¸¤æ¬¡ç»“æœç›¸åŒï¼Œåˆ™è¾“å‡ºï¼Œå¦åˆ™è¿›è¡Œç¬¬ä¸‰æ¬¡ç”„åˆ«ï¼Œä»¥å¤šæ•°ç»“æœä¸ºå‡†ï¼Œè‹¥æ— å¤šæ•°ç»“æœï¼Œåˆ™æç¤ºæ— æ³•åˆ¤æ–­
    åœ¨ç›®å‰çš„æç¤ºè¯ä¸‹ï¼Œæ¨¡å‹è¡¨ç°ç¨³å®šï¼Œè‹¥ä¸å¼€å¯é‡‡æ ·ï¼Œåˆ™ç¨³å¦¥æ¨¡å¼å’Œæ™®é€šæ¨¡å¼è¡¨ç°å‡ ä¹æ— å·®
    """ if SAFE_MODE else """
    By: stlin256 
    å½“å‰æ¨¡å¼: æ™®é€šæ¨¡å¼
    è¯´æ˜ï¼šæ¯æ¡çŸ­ä¿¡è¿›è¡Œä¸€æ¬¡ç”„åˆ«å¹¶è¾“å‡ºç»“æœï¼Œè‹¥æ¨¡å‹è¾“å‡ºæ ¼å¼å¼‚å¸¸åˆ™ä¼šè¿›è¡Œé‡è¯•ã€‚
    """

    with gr.Blocks(title="è¯ˆéª—çŸ­ä¿¡ç”„åˆ«ç³»ç»Ÿ") as demo:
        gr.Markdown("# è¯ˆéª—çŸ­ä¿¡ç”„åˆ«ç³»ç»Ÿ")
        gr.Markdown(mode_info)

        chatbot = gr.Chatbot(label="å¯¹è¯å†å²", type="messages", height=300, value=[
            {"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯è¯ˆéª—çŸ­ä¿¡ç”„åˆ«åŠ©æ‰‹ï¼Œè¯·è¾“å…¥çŸ­ä¿¡å†…å®¹ï¼Œæˆ‘ä¼šå¸®åŠ©ä½ åˆ¤æ–­æ˜¯å¦æ˜¯è¯ˆéª—çŸ­ä¿¡ã€‚"}
        ])
        state = gr.State(value=[{"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯è¯ˆéª—çŸ­ä¿¡ç”„åˆ«åŠ©æ‰‹ï¼Œè¯·è¾“å…¥çŸ­ä¿¡å†…å®¹ï¼Œæˆ‘ä¼šå¸®åŠ©ä½ åˆ¤æ–­æ˜¯å¦æ˜¯è¯ˆéª—çŸ­ä¿¡ã€‚"}])

        with gr.Row():
            sms_input = gr.Textbox(label="è¯·è¾“å…¥è¦åˆ†ç±»çš„çŸ­ä¿¡", placeholder="åœ¨æ­¤è¾“å…¥çŸ­ä¿¡å†…å®¹...")
            submit_btn = gr.Button("æäº¤")

        output_text = gr.Textbox(label="åˆ†ç±»ç»“æœ", interactive=False)

        submit_btn.click(
            fn=classify_sms,
            inputs=[sms_input, state],
            outputs=[output_text, chatbot]
        )

        clear_btn = gr.Button("æ¸…ç©ºå†å²")
        clear_btn.click(
            fn=lambda: ("", []),
            inputs=None,
            outputs=[output_text, chatbot]
        )

    return demo


# ========== ä¸»å‡½æ•° ==========
if __name__ == "__main__":
    interface = create_interface()
    interface.launch()